{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digits Data - KFold and Cross Val Score Exercise\n",
    "This exercise demonstartes one of the caveats of the train test split function. Each time the function is called on a given data set it splits the data differently leading to different test set scores - Including when stratify is called within the train_test_split funcrtion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9],\n",
       "       [178, 182, 177, 183, 181, 182, 181, 179, 174, 180]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count of unique target classes in the dataset\n",
    "unique, counts = np.unique(digits.target, return_counts=True)\n",
    "np.asarray((unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating traing and test splits to highlight caveat and for score comparison \n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size = 0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "       [56, 57, 48, 59, 70, 47, 50, 66, 41, 46]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count of unique target classes in the test set\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "np.asarray((unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model fit and score function \n",
    "# NOTE: SCORE IS NOT NECESSARILY THE BEST METRIC FOR PERCISION/F1 SCORE\n",
    "def get_score(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    return model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating classifiers with basic hyper parameters\n",
    "lr = LogisticRegression(max_iter=4000)\n",
    "svm = SVC(C=0.7)\n",
    "rfc = RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9703703703703703"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_score(lr, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9888888888888889"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_score(svm, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9740740740740741"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_score(rfc, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KFold cross validator\n",
    "Provides train/test indices to split data in train/test sets. Split dataset into k consecutive folds (without shuffling by default). Each fold is then used once as a validation while the k - 1 remaining folds form the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KFold Cross Validation\n",
    "from sklearn.model_selection import KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KFold(n_splits=3, random_state=None, shuffle=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiating KFold\n",
    "kf = KFold(n_splits=3)\n",
    "kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# For loop using train and test indexing of kfold splits\n",
    "lr_scores = []\n",
    "svm_scores = []\n",
    "rfc_scores = []\n",
    "\n",
    "\n",
    "for train_index, test_index in kf.split(digits.data):\n",
    "    X_train, X_test, y_train, y_test = digits.data[train_index], digits.data[test_index], digits.target[train_index], digits.target[test_index]\n",
    "    \n",
    "    lr_scores.append(get_score(lr, X_train, X_test, y_train, y_test))\n",
    "    svm_scores.append(get_score(svm, X_train, X_test, y_train, y_test))\n",
    "    rfc_scores.append(get_score(rfc, X_train, X_test, y_train, y_test))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9282136894824707, 0.9415692821368948, 0.9165275459098498]\n",
      "[0.9632721202003339, 0.9782971619365609, 0.9515859766277128]\n",
      "[0.9332220367278798, 0.9632721202003339, 0.9198664440734557]\n"
     ]
    }
   ],
   "source": [
    "print(lr_scores)\n",
    "print(svm_scores)\n",
    "print(rfc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified KFold \n",
    "This cross-validation object is a variation of KFold that returns stratified folds. The folds are made by preserving the percentage of samples for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StratifiedKFold(n_splits=3, random_state=None, shuffle=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiating StratifiedKFold \n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "skf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross val score\n",
    "Cross val score will do the same thing as the for loop above by creating train and test splits in the data (default 5) though the KFold and StratifiedKfold can also be added as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "# cross_val_score(estimator, X, y=None, *, groups=None, scoring=None, cv=None, n_jobs=None,\n",
    "    # verbose=0, fit_params=None, pre_dispatch='2*n_jobs', error_score=nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   3 out of   3 | elapsed:    8.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.92487479, 0.93823038, 0.92320534])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(lr, digits.data, digits.target, cv=skf,\n",
    "                scoring = 'accuracy', n_jobs=2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95555556, 0.94166667, 0.98050139, 0.98885794, 0.93593315])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(svm, digits.data, digits.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92777778, 0.92222222, 0.95264624, 0.96935933, 0.93593315])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(rfc, digits.data, digits.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross val score with custom scorer\n",
    "Using a combination of sklearns make_scorer, accuracy_score and classification_report to create a custom scorer which provides a basic accuracy score as well as recording the original and predicted classes in arrays to be called using classification report for a thorough breakdown of model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, accuracy_score, classification_report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_report(y_pred, y_true):\n",
    "    original_class.extend(y_true)\n",
    "    predicted_class.extend(y_pred)\n",
    "    return accuracy_score(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92821369, 0.94156928, 0.91652755])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_class = []\n",
    "predicted_class = []\n",
    "\n",
    "cross_val_score(lr, digits.data, digits.target, cv=kf, \n",
    "                scoring=make_scorer(get_class_report))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       181\n",
      "           1       0.92      0.85      0.88       197\n",
      "           2       0.93      0.98      0.96       168\n",
      "           3       0.91      0.94      0.92       177\n",
      "           4       0.94      0.96      0.95       178\n",
      "           5       0.95      0.94      0.94       183\n",
      "           6       0.97      0.95      0.96       185\n",
      "           7       0.92      0.95      0.94       173\n",
      "           8       0.89      0.89      0.89       175\n",
      "           9       0.88      0.88      0.88       180\n",
      "\n",
      "    accuracy                           0.93      1797\n",
      "   macro avg       0.93      0.93      0.93      1797\n",
      "weighted avg       0.93      0.93      0.93      1797\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(original_class, predicted_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
